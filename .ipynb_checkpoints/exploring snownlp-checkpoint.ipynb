{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring SnowNLP\n",
    "\n",
    "In this notebook, I explore the SnowNLP Python library that is written \n",
    "based on the Textblob Python library to analyze Chinese text instead of\n",
    "English text. I explore the utility of the functions and compare the \n",
    "accuracy of some SnowNLP functions to corresponding Textblob functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import snownlp (download link: https://github.com/isnowfy/snownlp)\n",
    "from snownlp import SnowNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the following functions are tested: `str.words`, `str.tags`, `str.pinyin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small example\n",
    "s = SnowNLP(u'我喜欢看电影。') # the 'u' ensures the string is unicode (not necessary for Python 3+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我', '喜欢', '看', '电影', '。']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separates unicode text based on phrases\n",
    "s.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('我', 'r'), ('喜欢', 'v'), ('看', 'v'), ('电影', 'n'), ('。', 'w')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigns tags to words (r: pronoun, v: verb, n: noun, w: punctuation)\n",
    "list(s.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wo', 'xi', 'huan', 'kan', 'dian', 'ying', '。']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds pinyin (without tones) for each word\n",
    "s.pinyin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional to Simpified \n",
    "\n",
    "Here I test out the function that processes traditional Chinese characters and produces an output of the corresponding simplified characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SnowNLP('漢語')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'汉语'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.han"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into Sentences\n",
    "\n",
    "Here is an example of how SnowNLP can be used to split a chunk of Chinese text into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['文化 清静 价 更 高 小 雷斯 的 母亲 看 着 小 雷 斯玩 了 很 长 时间',\n",
       " '便 哄 着 他 去 练琴',\n",
       " '对 他 说 亲爱 的',\n",
       " '快 去 琴房 练 钢琴',\n",
       " '练完 后 我 给 你 1 英镑 买 巧克力 吃',\n",
       " '小 雷斯嘟 着 嘴 说 可 隔壁 的 邻居 说',\n",
       " '如果 我 不 练琴',\n",
       " '他们 将 给 我 2 英镑']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SnowNLP('文化 清静 价 更 高 小 雷斯 的 母亲 看 着 小 雷 斯玩 了 很 长 时间 ， 便 哄 着 他 去 练琴 ， 对 他 说 亲爱 的 ， 快 去 琴房 练 钢琴 ！ 练完 后 我 给 你 1 英镑 买 巧克力 吃 。 小 雷斯嘟 着 嘴 说 可 隔壁 的 邻居 说 ， 如果 我 不 练琴 ， 他们 将 给 我 2 英镑 。')\n",
    "s.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above demonstration of `str.sentences` is on an example from Leiden Weibo Corpus. The presence of spaces in the splits sentences is a result of spaces in the original input of the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Keywords\n",
    "\n",
    "SnowNLP also has a `str.keywords()` function that takes an integer parameter and extracts that integer amount of keywords from the `str`. Similarly, `str.summary()` takes an integer parameter as well and extracts that integer amount of sentences from `str` that it believes best summarizes `str`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['练', '小', '雷斯', '英镑', '琴']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SnowNLP('文化 清静 价 更 高 小 雷斯 的 母亲 看 着 小 雷 斯玩 了 很 长 时间 ， 便 哄 着 他 去 练琴 ， 对 他 说 亲爱 的 ， 快 去 琴房 练 钢琴 ！ 练完 后 我 给 你 1 英镑 买 巧克力 吃 。 小 雷斯嘟 着 嘴 说 可 隔壁 的 邻居 说 ， 如果 我 不 练琴 ， 他们 将 给 我 2 英镑 。')\n",
    "s.keywords(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "The main function of SnowNLP that I will explore is it's ability to calculate sentiment in comparision with Textblob's sentiment calculations. The funciton `str.sentiments` does the trick in SnowNLP. Below I analyze the same Weibo corpus above and calculate the sentiment for each sentence in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999990110897581 文化 清静 价 更 高 小 雷斯 的 母亲 看 着 小 雷 斯玩 了 很 长 时间\n",
      "0.9239844197032276 便 哄 着 他 去 练琴\n",
      "0.8384346092683924 对 他 说 亲爱 的\n",
      "0.9590587243130785 快 去 琴房 练 钢琴\n",
      "0.9391460729160547 练完 后 我 给 你 1 英镑 买 巧克力 吃\n",
      "0.5935921936045641 小 雷斯嘟 着 嘴 说 可 隔壁 的 邻居 说\n",
      "0.9427240910332184 如果 我 不 练琴\n",
      "0.5714872631884823 他们 将 给 我 2 英镑\n"
     ]
    }
   ],
   "source": [
    "text = SnowNLP('文化 清静 价 更 高 小 雷斯 的 母亲 看 着 小 雷 斯玩 了 很 长 时间 ， 便 哄 着 他 去 练琴 ， 对 他 说 亲爱 的 ， 快 去 琴房 练 钢琴 ！ 练完 后 我 给 你 1 英镑 买 巧克力 吃 。 小 雷斯嘟 着 嘴 说 可 隔壁 的 邻居 说 ， 如果 我 不 练琴 ， 他们 将 给 我 2 英镑 。')\n",
    "sents = text.sentences\n",
    "\n",
    "for sent in sents:\n",
    "    s = SnowNLP(sent)\n",
    "    print(s.sentiments, str(sent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbasecondae1490f4aa9354e5b83a3f703fc46e1a5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
